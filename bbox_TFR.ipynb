{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddiki/miniconda3/envs/TF/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import dataset_util\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from convenience_funtions import *\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_string('output_path', '/home/siddiki/video2tfrecord/truck.tfrecords', 'Tf store directory')\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Truck_Single_1.mp4'\n",
    "cap = cv2.VideoCapture(filename)\n",
    "# Parameters to write to video\n",
    "out_filename = 'Truck_Single_1_Out' + \".avi\"\n",
    "out = cv2.VideoWriter(out_filename,cv2.VideoWriter_fourcc('M','J','P','G'), 5, (800,450))\n",
    "\n",
    "ret, old_frame = cap.read()\n",
    "old_frame = resize(old_frame, width=800)\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Parameters for Flow Calculation\n",
    "move_step = 16\n",
    "move_pix = 1.2 # How many pixels motion should be captured \n",
    "x_fac = 45 # x size of bounding box from center of object\n",
    "y_fac = 30   # y size of bounding box from center of object\n",
    "flow = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bbox(current_frame, old_frame, flow):\n",
    "    \n",
    "    ## Parameters\n",
    "    dict1 = {}\n",
    "    numbers = []  \n",
    "    final_bbox = []\n",
    "    central_coord = []\n",
    "    dist_px = []\n",
    "    flow_val = 0\n",
    "    central_x = 0\n",
    "    central_y = 0\n",
    "    \n",
    "    \n",
    "    flow = cv2.calcOpticalFlowFarneback(old_frame, current_frame, flow, pyr_scale=0.5, levels=3, winsize=15, iterations=3,\n",
    "                                        poly_n=5, poly_sigma=1.5, flags=0)\n",
    "\n",
    "    for y in range(0, flow.shape[0], move_step):\n",
    "\n",
    "        for x in range(0, flow.shape[1],move_step):\n",
    "            fx, fy = flow[y, x]\n",
    "\n",
    "            if abs(fx) >=move_pix or abs(fy) >=move_pix:\n",
    "                ##Store each point and its movement\n",
    "                dict1[(x,y)] = fx+fy\n",
    "#                 cv2.line(frame, (x, y), (int(x + fx), int(y + fy)), (255,0,0))\n",
    "\n",
    "    for key in dict1.keys():\n",
    "        numbers.append(key)\n",
    "\n",
    "    ## Find clusters that are close together\n",
    "    clusters = {}\n",
    "    dIndex = 0\n",
    "    for i in range(len(numbers) - 1):\n",
    "        distance = dist.euclidean(numbers[i], numbers[i+1])\n",
    "        if distance <= 120:\n",
    "            if not dIndex in clusters.keys(): clusters[dIndex] = []\n",
    "            clusters[dIndex].append(numbers[i])\n",
    "            clusters[dIndex].append(numbers[i + 1])\n",
    "            \n",
    "        else:\n",
    "            dIndex += 1\n",
    "            \n",
    "    ## Extract 1 bbox from each cluster\n",
    "\n",
    "    def getkey(item):\n",
    "        return item[0]\n",
    "\n",
    "    #print(\"Num clusters: \", len(clusters))\n",
    "    \n",
    "\n",
    "    if len(clusters) <=5:\n",
    "        for key in clusters:\n",
    "            val = clusters[key]\n",
    "            if len(val) >= 1:  # Multiple bbox\n",
    "                # Sort the val list\n",
    "                val = sorted(val, key=lambda element: (element[0], element[1]))\n",
    "                #Find average values in the cluster\n",
    "                for value in val:\n",
    "                    flow_val += abs(dict1[value])\n",
    "                    central_x += value[0]\n",
    "                    central_y += value[1]\n",
    "                flow_val =flow_val/len(val)\n",
    "                central_x = int(central_x/len(val))\n",
    "                central_y = int(central_y/len(val))\n",
    "\n",
    "                # Store values in a dictionary\n",
    "                dist_px.append(flow_val)\n",
    "                central_coord.append((central_x, central_y))\n",
    "\n",
    "                final_bbox.append((central_x-x_fac, central_x+x_fac, central_y-y_fac, central_y+y_fac))\n",
    "\n",
    "    return final_bbox, flow\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeVideo(frame, final_bbox):\n",
    "    for i in range(len(final_bbox)):\n",
    "        cv2.rectangle(frame, (final_bbox[i][0], final_bbox[i][2]), (final_bbox[i][1], final_bbox[i][3]), (0, 255, 0), 2)\n",
    "    out.write(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Records Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#float_list=tf.train.FloatList(value=value)\n",
    "#float_list=tf.train.FloatList(value=[value])\n",
    "'''\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "'''\n",
    "def create_tf_example(image, Bbox):\n",
    "  \n",
    "  height = frame.shape[0] # Image height\n",
    "  width = frame.shape[1] # Image width\n",
    "  depth = frame.shape[2] # Image depth\n",
    "    \n",
    "  image = np.asarray(image)  \n",
    "  encoded_image_data = image.tostring() # Encoded image bytes  \n",
    "\n",
    "  xmins = [Bbox[0][0]/800] # List of normalized left x coordinates in bounding box (1 per box)\n",
    "  xmaxs = [Bbox[0][1]/800] # List of normalized right x coordinates in bounding box\n",
    "             # (1 per box)\n",
    "  ymins = [Bbox[0][2]/450] # List of normalized top y coordinates in bounding box (1 per box)\n",
    "  ymaxs = [Bbox[0][3]/450] # List of normalized bottom y coordinates in bounding box\n",
    "             # (1 per box)\n",
    "  classes_text = [b'Truck'] # List of string class name of bounding box (1 per box)\n",
    "  classes = [1] # List of integer class id of bounding box (1 per box)\n",
    "  # TODO END\n",
    "  tf_label_and_data = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': dataset_util.int64_feature(height),\n",
    "      'image/width': dataset_util.int64_feature(width),\n",
    "      'image/depth': dataset_util.int64_feature(depth),      \n",
    "      'image/encoded': dataset_util.bytes_feature(encoded_image_data),      \n",
    "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "  }))\n",
    "  return tf_label_and_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.python_io.TFRecordWriter(FLAGS.output_path)\n",
    "\n",
    "while(1):\n",
    "    ret,frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = resize(frame, width=800)\n",
    "    current_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    bbox, flow = compute_bbox(old_gray, current_gray, flow)\n",
    "    \n",
    "    if not bbox:\n",
    "        break\n",
    "    \n",
    "    writeVideo(frame, bbox)\n",
    "    tf_example = create_tf_example(frame, bbox)\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "    \n",
    "    old_gray = current_gray.copy()\n",
    "    \n",
    "    \n",
    "\n",
    "writer.close()    \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
